{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d56ddb0b-d582-4b63-b51f-e7bb142a33cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac943d5-d66d-4820-9110-ab9035cb9ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors \n",
    "# pytorch opakowuje wielowymiarowe listy / macierze / tensory w swoją własną wewnętrzną strukturę danych Tensor \n",
    "data = [1,2,3]\n",
    "tensor = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b05f655e-7a87-4256-a687-a11de693c3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "#1 \n",
    "# TODO: utwórzy tensor o wymiarach 2x2 o wartościach 1 [https://pytorch.org/docs/stable/generated/torch.ones.html#torch-ones]\n",
    "# TODO: zapisz go do zmiennej tensor2d \n",
    "# TODO: wyświetl jego shape \n",
    "# TODO: Pomnóż nasz tensor2d przez 0.5 i zapisz wynik do tensor2d\n",
    "tensor2d = torch.ones((2,2))\n",
    "print(tensor2d.shape)\n",
    "tensor2d = tensor2d * 0.5\n",
    "print(tensor2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d528f8c6-eb00-468b-82ec-c299847f9953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4303, 0.4303],\n",
       "        [0.5190, 0.5190]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Utwórz randomowy tensor 2x2 [https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand]\n",
    "# TODO: przypisz go do zmiennej rand_tensor2d\n",
    "# Pomnóż randomowy tensor z naszym poprzednim \"połówkowym\" tensorem \n",
    "\n",
    "rand_tensor2d = torch.rand((2,2))\n",
    "torch.matmul(rand_tensor2d, tensor2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1feeafc2-41d1-4219-ad3e-c28bb8779a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptronA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear_layer1 = nn.Linear(10, 5)\n",
    "        self.linear_layer2 = nn.Linear(5, 1)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.linear_layer1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.linear_layer2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e657e8b5-33b7-4cff-96e5-996daea68ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utwórz instancję MultiLayerPerceptronA i przypisz do zmiennej model \n",
    "model = MultiLayerPerceptronA() # TODO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953847a2-a268-409d-88cb-b7967b97c77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5902], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: utwórz randomowy tensor o długości 10 i zaaplikuj na nim metodę forward() \n",
    "x = torch.rand(10)\n",
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e8f4edf-b164-4641-ab3e-801511d641b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatywną bardziej elegancką formą definiowania architektury jest użytwanie nn.Sequential \n",
    "\n",
    "class MultiLayerPerceptronB(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(10, 5),\n",
    "            nn.Sigmoid(),            \n",
    "            nn.Linear(5,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53eeedb6-3ce3-47cb-84e7-e4ee7a5f959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Utwórz MLP jak w definicji zadania korzystając z nn.Sequential \n",
    "\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(784, 50),\n",
    "            nn.Sigmoid(),            \n",
    "            nn.Linear(50, 15),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(15, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        return self.mlp(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9afb88fd-4099-497e-92b3-a23b2b6a470e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7015], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: stwórz instancję modelu \n",
    "model = MultiLayerPerceptron()\n",
    "model.forward(torch.rand(784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "102cf339-9cfb-4cc1-92c3-d27ab6a6d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp.0.weight\n",
      "tensor([[ 0.0273, -0.0321, -0.0336,  ..., -0.0083,  0.0059,  0.0140],\n",
      "        [ 0.0179, -0.0284, -0.0010,  ..., -0.0064,  0.0351, -0.0062],\n",
      "        [-0.0119,  0.0264, -0.0016,  ...,  0.0052, -0.0175, -0.0327],\n",
      "        ...,\n",
      "        [ 0.0273, -0.0266, -0.0204,  ..., -0.0094,  0.0028, -0.0234],\n",
      "        [ 0.0150, -0.0002,  0.0155,  ...,  0.0065,  0.0250, -0.0052],\n",
      "        [ 0.0084, -0.0223,  0.0147,  ...,  0.0327, -0.0136, -0.0252]])\n",
      "\n",
      "mlp.0.bias\n",
      "tensor([ 0.0295,  0.0099, -0.0169,  0.0141,  0.0343,  0.0178, -0.0050, -0.0313,\n",
      "        -0.0188,  0.0108, -0.0311, -0.0258, -0.0051, -0.0003, -0.0086, -0.0144,\n",
      "        -0.0339, -0.0085, -0.0300, -0.0004,  0.0047,  0.0072,  0.0072, -0.0067,\n",
      "        -0.0149,  0.0149,  0.0062,  0.0232, -0.0086,  0.0103,  0.0207,  0.0249,\n",
      "         0.0299,  0.0178,  0.0208,  0.0301,  0.0123,  0.0221, -0.0228, -0.0013,\n",
      "        -0.0274,  0.0239,  0.0119, -0.0231,  0.0064, -0.0245, -0.0314, -0.0120,\n",
      "         0.0177, -0.0287])\n",
      "\n",
      "mlp.2.weight\n",
      "tensor([[-3.4973e-03,  1.1681e-01, -1.3856e-01,  1.2973e-01,  9.1463e-03,\n",
      "         -2.3667e-03,  8.5057e-02,  3.0680e-03, -3.3167e-02,  9.9487e-02,\n",
      "         -4.9915e-02, -6.7119e-02,  8.1555e-02, -1.1885e-01,  1.0193e-01,\n",
      "         -4.4802e-02, -1.3050e-01, -8.6946e-02, -7.9799e-02, -1.6356e-02,\n",
      "          1.2782e-01, -1.0618e-01, -5.9811e-02,  7.6598e-02, -7.0400e-02,\n",
      "          1.2813e-01,  1.1438e-01,  1.0904e-01, -1.3353e-01, -1.0237e-01,\n",
      "          4.3711e-02, -5.7475e-02, -1.2218e-01,  6.0675e-02,  2.1409e-02,\n",
      "          4.7196e-03, -6.6085e-02,  1.9587e-02, -1.1239e-01,  3.5953e-02,\n",
      "          5.4710e-03,  1.2567e-01,  1.0741e-02, -6.4121e-02, -5.6227e-02,\n",
      "          1.3691e-01,  5.9933e-05,  7.0357e-02,  1.1423e-01,  8.1892e-02],\n",
      "        [ 6.7568e-02,  6.1465e-02, -4.9152e-02, -6.9835e-02,  1.2856e-01,\n",
      "          1.0158e-01,  7.3256e-02,  1.0956e-01, -5.0250e-02,  4.0612e-02,\n",
      "          2.7653e-03, -1.0636e-01, -7.9576e-02, -9.8685e-02, -8.3007e-02,\n",
      "          8.8492e-02,  9.9366e-02,  1.2291e-02,  4.3579e-02,  1.2011e-01,\n",
      "         -3.8407e-02,  7.5844e-03, -1.2074e-01,  1.0558e-01,  2.2518e-04,\n",
      "         -3.5812e-02, -1.1330e-01, -2.5419e-02, -8.2265e-02,  1.0195e-01,\n",
      "          1.3435e-02, -6.1240e-02,  3.1138e-02, -1.1621e-01,  3.7102e-02,\n",
      "          4.0414e-02,  8.6063e-02, -3.4250e-02,  6.3206e-02, -1.2763e-01,\n",
      "          5.3018e-02, -1.1243e-01, -1.3932e-01,  1.1967e-01,  1.2300e-01,\n",
      "         -3.9761e-02,  6.7975e-02, -5.0295e-02,  3.4830e-02, -6.3734e-02],\n",
      "        [ 9.2624e-02, -8.3604e-02, -5.0476e-02, -1.0504e-01,  2.8357e-02,\n",
      "         -1.0704e-01,  1.0203e-01,  4.9976e-02, -1.4047e-01, -1.1002e-01,\n",
      "         -1.1132e-01, -3.9338e-02,  1.8908e-02,  3.5704e-02, -2.4828e-04,\n",
      "          5.2235e-02,  1.1138e-01,  1.0954e-01,  3.8032e-02, -1.3854e-01,\n",
      "         -4.4415e-02,  8.7326e-02, -1.1142e-01, -7.3306e-03,  1.3520e-01,\n",
      "          2.2181e-03,  2.4433e-02, -3.2945e-02, -1.7111e-02,  1.0979e-02,\n",
      "          1.2783e-01,  5.2856e-04,  1.2620e-01, -1.3998e-01, -1.1555e-01,\n",
      "         -1.3870e-01,  1.3591e-01, -7.7021e-02,  5.0856e-02, -7.0958e-02,\n",
      "          1.3372e-01, -2.1673e-02, -4.2832e-02, -5.0850e-02,  3.3296e-03,\n",
      "         -1.1142e-01, -1.2009e-01,  4.7464e-02, -1.2396e-01, -8.2581e-02],\n",
      "        [ 8.5115e-03,  1.0083e-01,  1.2530e-01,  5.0549e-02,  2.0518e-02,\n",
      "          3.3144e-02, -9.5992e-02,  1.0459e-01, -7.2291e-02,  3.7060e-02,\n",
      "         -2.2455e-02,  8.1987e-02, -1.0494e-01,  1.2271e-01,  1.1347e-01,\n",
      "         -1.7118e-03,  2.7145e-02, -4.6876e-02, -1.0093e-01, -1.0495e-02,\n",
      "         -7.0081e-02, -9.0181e-02,  6.8749e-02, -9.5199e-02, -8.1678e-02,\n",
      "         -1.4815e-02, -1.0845e-01, -9.0686e-02, -1.2670e-01, -1.1802e-01,\n",
      "         -4.3877e-02,  1.0541e-01, -7.8880e-02,  1.1137e-01,  1.2053e-01,\n",
      "          4.6200e-02, -2.8465e-02,  1.0808e-01, -4.3083e-02, -1.1035e-01,\n",
      "         -1.0573e-01, -9.8824e-02,  1.2161e-01,  6.2910e-02,  5.0618e-02,\n",
      "         -5.3327e-03,  1.1767e-01, -4.9278e-02,  4.5626e-02,  3.0274e-02],\n",
      "        [ 6.2431e-02,  1.1835e-01,  6.5625e-02, -1.2006e-01, -1.0342e-01,\n",
      "          6.8152e-02, -9.8118e-02,  3.2225e-02, -2.2287e-02,  1.0910e-01,\n",
      "         -7.9487e-02,  1.2399e-01, -7.1898e-02, -5.9652e-02,  1.3147e-01,\n",
      "         -1.1285e-01,  8.1119e-03,  1.1832e-01,  6.3564e-03, -1.2737e-01,\n",
      "          2.2076e-02,  1.3053e-01,  1.5719e-03,  1.2689e-01, -1.2898e-01,\n",
      "          3.4486e-02, -3.4138e-02, -7.2122e-05,  3.8493e-02, -2.0808e-02,\n",
      "          4.5460e-02,  1.0672e-01, -2.5078e-02,  1.0531e-01, -4.9134e-02,\n",
      "          3.6988e-02,  9.8770e-02, -7.5852e-02, -1.2871e-01, -1.1161e-01,\n",
      "          9.6745e-02,  1.1830e-01, -2.1764e-02,  1.1128e-01,  5.2492e-02,\n",
      "          3.3025e-02,  1.1185e-01,  1.9043e-02, -7.1799e-02,  1.8914e-02],\n",
      "        [ 6.9564e-02, -9.3867e-02, -4.6824e-02,  7.3660e-02,  1.3436e-01,\n",
      "          8.6084e-02, -1.1021e-01,  9.4968e-02, -9.2232e-02,  1.2518e-01,\n",
      "          1.0255e-01, -2.9073e-02, -7.0781e-04, -3.8037e-02, -5.4899e-02,\n",
      "          1.2548e-01, -1.0329e-01,  1.3369e-01,  6.8070e-02,  8.0157e-02,\n",
      "         -1.3697e-01,  3.7506e-02, -5.1854e-02, -1.1243e-01,  7.3909e-02,\n",
      "         -2.5937e-02,  1.0850e-01, -4.4284e-02, -1.5716e-02, -1.7739e-02,\n",
      "         -4.9454e-02, -4.7379e-02, -1.0513e-01,  1.0791e-02, -1.1792e-01,\n",
      "         -6.3875e-02, -1.1849e-01,  1.2560e-01, -1.1903e-01,  4.9584e-02,\n",
      "          1.1879e-02, -7.5891e-02, -1.6552e-02,  4.9248e-02, -9.0042e-02,\n",
      "         -6.3515e-02,  1.2282e-01,  2.5520e-02,  7.6438e-03,  1.8217e-02],\n",
      "        [-5.6525e-02, -1.0530e-01,  1.2728e-01, -6.8856e-02, -1.7169e-02,\n",
      "         -8.0342e-02, -1.7145e-02, -8.0485e-02, -7.9144e-03, -5.1970e-02,\n",
      "          9.3078e-02,  1.2551e-02, -2.7696e-02, -3.4849e-02,  1.8985e-03,\n",
      "          8.7754e-02,  5.2553e-02,  9.6169e-03,  8.5275e-02, -1.2688e-01,\n",
      "          5.5969e-02, -5.2442e-02,  1.0380e-01,  8.7717e-02, -5.1659e-02,\n",
      "          7.5997e-02, -1.2471e-02, -8.5568e-02,  1.0069e-01, -5.8150e-02,\n",
      "          8.2931e-02, -8.4151e-02,  1.5597e-02, -1.1851e-01,  1.0726e-01,\n",
      "         -5.4449e-02, -1.2416e-01,  6.7587e-02,  5.7780e-02, -1.3094e-01,\n",
      "         -7.8428e-02, -1.2540e-01,  1.2222e-01, -5.4303e-02,  3.5750e-02,\n",
      "          1.0096e-01, -3.2004e-02, -9.7381e-02, -7.1464e-02, -1.2350e-01],\n",
      "        [ 1.1801e-01,  4.8995e-02, -1.0232e-01, -3.9760e-02,  8.8863e-03,\n",
      "         -2.4265e-02,  7.7469e-02, -1.3153e-01,  4.4084e-02, -1.1233e-01,\n",
      "          1.3733e-01, -5.2015e-02,  5.8076e-02, -5.1808e-02, -9.8955e-02,\n",
      "          3.1664e-03,  5.9067e-02, -4.5181e-02,  7.3071e-02, -1.3442e-01,\n",
      "         -4.7750e-02, -1.2297e-01, -2.9052e-02,  6.4374e-02, -1.0118e-01,\n",
      "         -8.8103e-02, -6.3020e-02,  6.8993e-02, -1.3062e-01, -4.1853e-02,\n",
      "          1.2944e-01, -1.3439e-01, -1.0153e-01, -4.1147e-02, -1.4719e-03,\n",
      "         -9.5462e-02,  7.6472e-02, -1.1530e-01, -9.0995e-02, -1.2218e-01,\n",
      "          1.3744e-01, -1.1718e-01, -3.9619e-03,  5.9796e-02, -5.7879e-02,\n",
      "          8.9649e-02,  1.3471e-02,  8.9171e-02, -1.1264e-01, -7.0330e-02],\n",
      "        [ 1.1633e-02, -1.1958e-01, -8.5222e-02,  1.0765e-01,  1.2755e-01,\n",
      "         -3.9476e-02,  5.9667e-02,  8.3940e-02, -3.1543e-02, -1.0065e-01,\n",
      "         -2.1104e-03, -1.3095e-01,  6.3738e-02, -8.2074e-02, -1.3198e-01,\n",
      "          5.2677e-03,  1.2161e-01, -2.0136e-02,  1.1194e-02,  9.7473e-02,\n",
      "         -6.0349e-02,  2.3455e-02, -1.7529e-02,  5.4104e-02,  9.4332e-02,\n",
      "          1.0714e-01,  1.0567e-01,  6.8012e-02,  1.3032e-01, -6.8806e-02,\n",
      "          1.3767e-02, -1.3452e-01, -1.0186e-01,  1.0720e-01,  1.2266e-01,\n",
      "          2.0228e-02, -8.6661e-02,  9.9485e-02, -7.9627e-02,  5.0813e-02,\n",
      "         -2.7596e-02,  5.0477e-02,  2.3270e-02, -4.3600e-02, -9.2924e-03,\n",
      "         -1.2255e-01,  1.3205e-01, -5.8616e-03, -9.0302e-02,  1.4032e-01],\n",
      "        [-7.9090e-02, -3.4961e-02,  1.2817e-01, -1.1230e-01, -8.0233e-02,\n",
      "          1.3004e-01, -1.2528e-01, -2.8553e-02, -1.1371e-01, -6.8901e-02,\n",
      "         -9.4456e-02, -5.6404e-02,  6.7267e-02, -4.4299e-02,  4.5852e-02,\n",
      "         -1.0038e-01, -1.5408e-02, -9.2051e-03, -1.0491e-01, -5.8683e-03,\n",
      "          4.2226e-02, -8.1365e-02,  1.3576e-02,  5.1330e-02,  1.3070e-01,\n",
      "          1.4790e-02,  4.1403e-02, -1.1689e-01,  8.3282e-02, -5.7151e-02,\n",
      "         -1.0378e-01, -5.8418e-02, -1.1870e-01,  1.0559e-01, -9.7365e-02,\n",
      "         -7.2897e-02,  9.4757e-02, -8.8803e-02,  1.1105e-01,  3.5684e-02,\n",
      "         -1.2104e-01,  7.7958e-02, -2.7864e-02, -1.2206e-01,  5.6000e-02,\n",
      "         -1.1436e-01, -5.1957e-02, -5.7602e-02,  5.8970e-02, -7.7165e-02],\n",
      "        [ 1.1869e-01,  7.3298e-02, -3.1441e-02, -5.4699e-02, -8.8220e-02,\n",
      "         -9.2490e-02, -4.9897e-02, -2.6579e-02, -8.8801e-02,  9.4094e-02,\n",
      "         -9.3723e-02,  7.6946e-02,  1.0363e-02,  7.4998e-02,  8.3731e-02,\n",
      "          5.9875e-02,  5.0025e-02,  1.2080e-02,  1.1070e-01, -1.2527e-01,\n",
      "          3.7342e-02, -5.8759e-02,  8.5626e-02, -3.0018e-02, -1.0829e-01,\n",
      "          1.0297e-01,  7.5156e-02,  8.8059e-02, -8.0225e-02, -3.3305e-02,\n",
      "          1.1593e-01, -8.0908e-02, -6.1611e-02, -2.5715e-02,  1.2598e-01,\n",
      "         -1.7876e-02,  7.8822e-02,  1.1824e-01,  1.2300e-01,  2.8200e-02,\n",
      "          9.9539e-02,  1.0734e-02, -2.0856e-02,  1.1396e-01, -3.6170e-02,\n",
      "          4.6875e-02,  1.7135e-02, -9.2983e-02, -2.8107e-03,  4.6545e-02],\n",
      "        [-7.7080e-02,  3.5306e-02,  1.8122e-02, -3.7757e-03,  8.6137e-02,\n",
      "          4.3251e-02,  1.2828e-01,  5.2892e-02, -1.0129e-01,  1.1667e-01,\n",
      "          1.3390e-01, -6.0643e-02,  4.2256e-02, -3.1735e-02, -5.3674e-03,\n",
      "          4.3647e-02,  4.3050e-02,  5.8085e-02, -3.5684e-02, -5.7029e-03,\n",
      "          1.0948e-01,  2.0147e-02, -1.2290e-01,  1.2824e-01,  3.9457e-02,\n",
      "         -3.6834e-02, -1.4074e-01, -1.3455e-01, -1.2588e-02, -5.6242e-02,\n",
      "         -1.3895e-01,  5.4136e-02,  9.3915e-02, -9.0841e-02, -1.8207e-02,\n",
      "         -8.3626e-02,  2.0295e-02, -9.8837e-02, -8.5407e-02,  1.2124e-01,\n",
      "          1.3492e-01,  3.6411e-02,  4.1303e-02, -8.5518e-02, -5.9604e-02,\n",
      "          7.4190e-02,  5.9657e-02,  4.8981e-03, -9.1954e-02,  1.9862e-02],\n",
      "        [-8.9546e-02,  1.1292e-01, -3.9100e-02, -7.1544e-02,  1.2364e-01,\n",
      "          7.4481e-02, -1.3563e-01, -6.6803e-02,  6.1848e-02, -5.0517e-02,\n",
      "          2.6337e-02, -3.2335e-02,  3.3784e-02,  6.3898e-02,  1.1160e-01,\n",
      "          1.2629e-01,  1.3382e-01, -9.1744e-02, -1.0081e-01, -1.3717e-01,\n",
      "         -5.6701e-02, -1.0696e-01, -4.0522e-02,  9.6498e-02, -4.1206e-02,\n",
      "          1.0452e-02,  3.7218e-02, -8.4444e-02, -1.3578e-01, -2.3387e-03,\n",
      "         -1.1205e-01,  1.1907e-01,  5.3705e-02,  8.6881e-02,  6.5906e-02,\n",
      "          1.2908e-01,  5.0405e-02, -1.3475e-01,  2.3168e-02,  3.3346e-02,\n",
      "         -5.2970e-02, -2.4014e-02, -8.4527e-02,  1.3162e-01, -1.3398e-01,\n",
      "          1.3185e-01,  6.2078e-02, -4.5294e-02, -2.8539e-02,  5.4214e-02],\n",
      "        [ 6.5583e-02,  7.0530e-02,  4.5606e-03,  7.0908e-02, -2.3063e-02,\n",
      "          9.0802e-02, -1.1563e-01, -1.2658e-01,  3.6047e-02, -7.6215e-02,\n",
      "          2.0962e-02, -6.7130e-03, -1.3155e-01,  5.9731e-02,  4.0678e-02,\n",
      "          1.2333e-01, -6.8271e-02,  3.5377e-02, -1.0625e-01, -8.2558e-02,\n",
      "         -2.9268e-02, -1.0859e-01,  1.1821e-01, -5.7536e-02, -1.7792e-03,\n",
      "          4.3497e-02,  3.7671e-02, -2.9237e-02,  6.1375e-02, -8.9382e-02,\n",
      "         -1.0530e-01, -5.0014e-02, -9.0150e-02,  8.9151e-02, -1.2564e-01,\n",
      "          1.0988e-01, -1.3614e-01, -1.9449e-02, -4.9664e-02, -9.3470e-02,\n",
      "         -5.6906e-02, -8.3794e-02, -1.3612e-02,  4.9629e-02, -4.8068e-02,\n",
      "         -1.0988e-02,  2.5649e-02,  1.0712e-01, -7.9132e-02, -4.6836e-02],\n",
      "        [ 5.4101e-02, -1.2229e-01, -1.0236e-01,  1.2703e-01, -1.0925e-01,\n",
      "         -5.4001e-03,  3.3316e-02,  7.1283e-03, -1.0919e-01, -7.2599e-02,\n",
      "         -1.1126e-01,  1.0501e-01,  1.0077e-01,  1.3064e-01, -9.1606e-02,\n",
      "         -1.4500e-02,  1.0396e-01,  1.3204e-01, -1.1853e-01, -1.0917e-01,\n",
      "          9.0980e-02, -1.2065e-01,  2.0034e-02, -8.5420e-03,  1.2190e-01,\n",
      "         -9.0879e-02,  3.7008e-02,  1.3473e-01,  1.0120e-01, -9.9760e-02,\n",
      "         -1.2833e-01,  3.5705e-02, -1.1723e-01, -1.3138e-01,  2.0650e-02,\n",
      "          1.4119e-01,  6.0623e-02, -1.7982e-02,  1.2703e-01, -1.3115e-01,\n",
      "         -4.5326e-02, -3.7388e-02,  9.2169e-02,  1.0999e-01,  1.2204e-01,\n",
      "         -9.1752e-02, -3.9030e-02, -6.1664e-02,  2.1129e-02, -9.6306e-02]])\n",
      "\n",
      "mlp.2.bias\n",
      "tensor([-0.1090,  0.0485, -0.0564, -0.0012,  0.0157, -0.0956,  0.1280, -0.0659,\n",
      "        -0.0338, -0.0696,  0.0761,  0.0553, -0.0114,  0.0344,  0.1340])\n",
      "\n",
      "mlp.4.weight\n",
      "tensor([[-0.0294,  0.0645,  0.2579,  0.0028,  0.1319,  0.2117,  0.1545, -0.1254,\n",
      "          0.2011,  0.1521,  0.2400,  0.1404,  0.2015, -0.1355, -0.0667]])\n",
      "\n",
      "mlp.4.bias\n",
      "tensor([0.1395])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parametry utworzonej sieci \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)\n",
    "        print(param.data)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "730a08cc-16fe-4d16-81e9-e908d029a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nasz model z wczoraj też może być wyrażony w Pytorch - technicznie to też \"bardzo prosta\" sieć neuronowa \n",
    "\n",
    "class ToyMLModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2, 1, bias=False)            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        return self.mlp(x)\n",
    "\n",
    "toy = ToyMLModel()\n",
    "state_dict = toy.state_dict()\n",
    "state_dict['mlp.0.weight'] = torch.Tensor([[-12500, 24000]])\n",
    "toy.load_state_dict(state_dict);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63291a58-7dc8-4a43-8a2b-f27308f5ff04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([835000.], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy.forward(torch.Tensor([10, 40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb044f-dc52-451c-b634-7265a95d9271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
